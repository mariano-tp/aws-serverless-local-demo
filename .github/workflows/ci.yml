name: ci
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      localstack:
        image: localstack/localstack:3
        env:
          SERVICES: s3,sqs,dynamodb
          DEBUG: "1"
        ports:
          - 4566:4566
        options: >-
          --health-cmd="curl -sf http://localhost:4566/_localstack/health || exit 1"
          --health-interval=5s
          --health-timeout=2s
          --health-retries=120

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Wait for LocalStack
        shell: bash
        run: |
          set -euxo pipefail
          for i in {1..90}; do
            if curl -sf http://localhost:4566/_localstack/health | jq -e '.services.s3=="available" and .services.sqs=="available" and .services.dynamodb=="available"' >/dev/null; then
              echo "LocalStack ready"; break
            fi
            sleep 2
          done

      - name: Bootstrap (S3 -> SQS) + DynamoDB
        env:
          AWS_DEFAULT_REGION: us-east-1
          AWS_ACCESS_KEY_ID: test
          AWS_SECRET_ACCESS_KEY: test
          ENDPOINT: http://localhost:4566
        shell: bash
        run: |
          set -euxo pipefail

          # Create S3 bucket
          aws --endpoint-url="$ENDPOINT" s3api create-bucket --bucket events-bucket || true

          # Create SQS queue
          QUEUE_URL=$(aws --endpoint-url="$ENDPOINT" sqs create-queue --queue-name events-queue --query 'QueueUrl' --output text)
          QUEUE_ARN=$(aws --endpoint-url="$ENDPOINT" sqs get-queue-attributes --queue-url "$QUEUE_URL" --attribute-names QueueArn --query 'Attributes.QueueArn' --output text)

          # Allow S3 to send to the SQS queue
          cat > policy.json <<'JSON'
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Sid": "AllowS3SendMessage",
                "Effect": "Allow",
                "Principal": { "Service": "s3.amazonaws.com" },
                "Action": "SQS:SendMessage",
                "Resource": "ARN_PLACEHOLDER",
                "Condition": {
                  "ArnLike": { "aws:SourceArn": "arn:aws:s3:::events-bucket" }
                }
              }
            ]
          }
          JSON
          sed -i "s|ARN_PLACEHOLDER|$QUEUE_ARN|g" policy.json
          jq -n --argjson p "$(cat policy.json)" '{Policy: ($p|tojson)}' > attrs.json
          aws --endpoint-url="$ENDPOINT" sqs set-queue-attributes --queue-url "$QUEUE_URL" --attributes file://attrs.json

          # Configure S3 -> SQS notifications
          cat > notif.json <<JSON
          {
            "QueueConfigurations": [
              {
                "QueueArn": "$QUEUE_ARN",
                "Events": ["s3:ObjectCreated:*"]
              }
            ]
          }
          JSON
          aws --endpoint-url="$ENDPOINT" s3api put-bucket-notification-configuration --bucket events-bucket --notification-configuration file://notif.json

          # Create DynamoDB table
          aws --endpoint-url="$ENDPOINT" dynamodb create-table             --table-name events             --attribute-definitions AttributeName=id,AttributeType=S             --key-schema AttributeName=id,KeyType=HASH             --billing-mode PAY_PER_REQUEST || true

      - name: Run tests
        env:
          AWS_DEFAULT_REGION: us-east-1
          AWS_ACCESS_KEY_ID: test
          AWS_SECRET_ACCESS_KEY: test
          LOCALSTACK_ENDPOINT: http://localhost:4566
          PYTHONPATH: ${{ github.workspace }}
        run: pytest -q
